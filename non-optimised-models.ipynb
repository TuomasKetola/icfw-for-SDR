{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac526461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nJupyter file to perform the non-optimised re-ranking task for ECIR 2023 paper \\ntitled: Automatic and Analytical Field Weighting for Structured Document Retrieval\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Jupyter file to perform the non-optimised re-ranking task for ECIR 2023 paper \n",
    "titled: Automatic and Analytical Field Weighting for Structured Document Retrieval\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfb0ca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bedf20e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_json(path):\n",
    "    \"\"\"\n",
    "    function to open .json files\n",
    "    \"\"\"\n",
    "    with open(path, 'r') as in_:\n",
    "        f = json.load(in_)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caf8e856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ndcg(query_id, ranking, q_qrels,k=100):\n",
    "    \"\"\"\n",
    "    calculate ndcg@k for a given value of k\n",
    "    \"\"\"\n",
    "    \n",
    "    true_relevance = []\n",
    "    prediction = []\n",
    "    qrel_doc_ids = [x[2] for x in q_qrels]\n",
    "    prediction_doc_ids = list(ranking.keys())\n",
    "    for qrel in q_qrels:\n",
    "        doc_id = qrel[2]\n",
    "        true_relevance.append(float(qrel[3]))\n",
    "        try:\n",
    "            prediction.append(ranking[doc_id])\n",
    "        except KeyError:\n",
    "            prediction.append(0)\n",
    "        \n",
    "    for doc_id in list(set(prediction_doc_ids) - set(qrel_doc_ids)):\n",
    "        prediction.append(ranking[doc_id])\n",
    "        true_relevance.append(0)\n",
    "    try:\n",
    "        acc = ndcg_score(np.array([true_relevance]), np.array([prediction]),k=k)\n",
    "        acc = round(acc,5)\n",
    "    except:\n",
    "        print(true_relevance)\n",
    "        print(prediction)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70dc237e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ap(query_id, q_ranking, q_qrels):\n",
    "    \"\"\"\n",
    "    calculate average precision\n",
    "    \"\"\"\n",
    "    true_relevance = []\n",
    "    prediction = []\n",
    "    qrel_doc_ids = [x[2] for x in q_qrels]\n",
    "    prediction_doc_ids = list(q_ranking.keys())\n",
    "    no_info_count = 0\n",
    "    fail = False\n",
    "    for qrel in q_qrels:\n",
    "        doc_id = qrel[2]\n",
    "        true_relevance.append(float(qrel[3]))\n",
    "        # if qrel doc not found, add as 0 to prediction\n",
    "        try:\n",
    "            prediction.append(q_ranking[doc_id])\n",
    "        except KeyError:\n",
    "            prediction.append(0)\n",
    "    len_rel = len(prediction)\n",
    "    for doc_id in list(set(prediction_doc_ids) - set(qrel_doc_ids)):\n",
    "        prediction.append(q_ranking[doc_id])\n",
    "        true_relevance.append(0)\n",
    "\n",
    "\n",
    "    aps = []\n",
    "    true_relevance = [0 if x < 1 else 1 for x in true_relevance]\n",
    "\n",
    "    trues = np.array(true_relevance)\n",
    "    preds = np.array(prediction)\n",
    "    ap = average_precision_score(trues, preds)\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "384aceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k_score(y_true, y_pred_proba, k=10, pos_label=1):\n",
    "    \"\"\"\n",
    "    calculate precision@k for a given value of k\n",
    "    \"\"\"\n",
    "    topk = [\n",
    "        y_true_ == pos_label \n",
    "        for y_true_, y_pred_proba_ \n",
    "        in sorted(\n",
    "            zip(y_true, y_pred_proba), \n",
    "            key=lambda y: y[1], \n",
    "            reverse=True\n",
    "        )[:k]\n",
    "    ]\n",
    "    return sum(topk) / len(topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2d6c1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_q_based(index_name, acc, lst, model):\n",
    "    \"\"\"\n",
    "    function that dumps accuracies\n",
    "    \"\"\"\n",
    "    if not catch_all:\n",
    "        q_acc_save_path = os.path.join(q_acc_dir,'acc-nonsuper-'+index_name+'_{}_'+ '{}_'+'base.csv')\n",
    "    else:\n",
    "        q_acc_save_path = os.path.join(q_acc_dir,'acc-nonsuper-'+index_name+'_{}_'+ '{}_'+'catch_all.csv')\n",
    "    with open(q_acc_save_path.format(model, acc),'w') as out:\n",
    "        writer = csv.writer(out)\n",
    "        writer.writerows(zip(all_query_data.keys(),lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "302da31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of index\n",
    "index_name = 'trec-web'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d487999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if True a catchall field is used\n",
    "catch_all = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9640ec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_dict = {'ndcg10':{},'ndcg100':{}, 'map':{}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02a7e8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory where query based accuracies are saved\n",
    "q_acc_dir = 'q_based_accs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb01a174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data directory\n",
    "data_dir = 'data/{}/'.format(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "392e0ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# information regarding datasets necessary for calculations\n",
    "datasetInfo = {\n",
    "    'dbpedia':{\n",
    "        \"empty_fields\": {\n",
    "            \"similar_entities\": 1869980,\n",
    "            \"label\": 940,\n",
    "            \"attributes\": 0,\n",
    "            \"categories\": 41688,\n",
    "            \"related_entities\": 1832508,\n",
    "            \"all\": 0\n",
    "    },\n",
    "        \"total_doc_count\":4641889\n",
    "        },\n",
    "    'trec-web':{\n",
    "         \"empty_fields\": {\n",
    "             \"title\": 3062,\n",
    "             \"body\": 361,\n",
    "             \"all\": 0\n",
    "     },\n",
    "         \"total_doc_count\":212591\n",
    "    },\n",
    "    'homedepot': {\n",
    "\n",
    "         \"empty_fields\": {\n",
    "             \"product_uid\": 0,\n",
    "             \"product_name\": 0,\n",
    "             \"product_description\": 0,\n",
    "             \"product_attributes\": 16263,\n",
    "             \"all\": 0\n",
    "             \n",
    "     },\n",
    "         \"total_doc_count\": 54668,\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d11f5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile a field-based dictionaries\n",
    "field_dict = {\n",
    "    'trec-web':['title', 'body'],\n",
    "    'homedepot':['product_name', 'product_description','product_attributes'],\n",
    "    'dbpedia': [\"label\" , \"attributes\" , \"categories\" , \"related_entities\", \"similar_entities\"]\n",
    " }\n",
    "avg_fl_dict = {\n",
    "    field: None for field in field_dict[index_name]\n",
    "}\n",
    "fields = field_dict[index_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed8388f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load query based qrels\n",
    "qrel_dict = defaultdict(list)\n",
    "qrel_file_path = 'qrels-{}.all'.format(index_name)\n",
    "with open(qrel_file_path, 'r') as in_:\n",
    "    reader = csv.reader(in_, delimiter='\\t')\n",
    "    qrel_file = list(reader)\n",
    "for qrel in qrel_file:\n",
    "    qrel[2] = qrel[2].lower()\n",
    "    qrel_dict[qrel[0].strip()].append(qrel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a609a7",
   "metadata": {},
   "source": [
    "\n",
    "### put all the relevant info into arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80e4c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell loops over the queries and compiles a query_data dictionary for each\n",
    "# In this dictionary all the needed metrics data is stored for calculations later on\n",
    "all_query_data = {}\n",
    "for q_file_name in os.listdir(data_dir):\n",
    "    if 'pickle' in q_file_name:\n",
    "        continue\n",
    "    q_data = open_json(os.path.join(data_dir,q_file_name))\n",
    "    q_id = q_data['query_id'].strip()\n",
    "    field_idfs = q_data['q_term_idfs']\n",
    "    field_dfs = q_data['q_term_dfs']\n",
    "#     field_Ns = q_data['fieldNs']\n",
    "    field_Ns = {\n",
    "        field: datasetInfo[index_name]['total_doc_count'] - datasetInfo[index_name]['empty_fields'][field]\n",
    "        for field in fields}\n",
    "    terms = q_data['query'].split(' ')\n",
    "    results = q_data['results']\n",
    "    field_tfs = {field: [] for field in fields}\n",
    "    field_lengths = {field: [] for field in fields}\n",
    "    field_scores = {field: [] for field in fields}\n",
    "\n",
    "    doc_ids = []\n",
    "    bm25f_score_lst = []\n",
    "    concat_dls = []\n",
    "    for document, data in results.items():\n",
    "        doc_ids.append(document)\n",
    "        bm25f_score_lst.append(q_data['bm25f_score'])\n",
    "        for field in fields:\n",
    "\n",
    "            doc_field_data = data[field]\n",
    "\n",
    "            tf_vect = [doc_field_data['term_tfs'][term]  for term in terms]\n",
    "\n",
    "            fl = doc_field_data['fl']\n",
    "            score = doc_field_data['score']\n",
    "            field_tfs[field].append(tf_vect)\n",
    "            field_lengths[field].append(fl)\n",
    "            field_scores[field].append(score)\n",
    "            if doc_field_data['avgfl']:\n",
    "                avg_fl_dict[field] = doc_field_data['avgfl']\n",
    "    \n",
    "\n",
    "    field_tfs = np.dstack(list(field_tfs.values()))\n",
    "    \n",
    "    field_scores_= np.array(list(field_scores.values())).T\n",
    "\n",
    "    # doc lenghths\n",
    "    field_lengths = np.array(list(field_lengths.values())).T\n",
    "    field_lengths = field_lengths.reshape((len(results),1,len(fields)))\n",
    "    q_data['tf_arr'] = field_tfs\n",
    "    q_data['fl_arr'] = field_lengths\n",
    "    q_data['avgfl'] = np.array(list(avg_fl_dict.values())).reshape(1,1,len(fields))\n",
    "    q_data['bm25f_scores'] = dict(zip(q_data['bm25f_doc_ids'],q_data['bm25f_score']))\n",
    "\n",
    "    # idfs\n",
    "    idfs = np.dstack(\n",
    "        [\n",
    "            [field_idfs[field][t] if t in field_idfs[field].keys() else 0.0 for t in terms]\n",
    "            for field in fields\n",
    "        ])\n",
    "    \n",
    "    # global idfs\n",
    "    global_idfs = np.array([\n",
    "        q_data['global_idfs'][term] if term in q_data['global_idfs'].keys() else 0 for term in terms\n",
    "    ]).reshape(1,len(terms))\n",
    "    \n",
    "    # global dfs \n",
    "    global_dfs = np.array([\n",
    "        q_data['global_dfs'][term] if term in q_data['global_dfs'].keys() else 0 for term in terms\n",
    "    ]).reshape(1,len(terms))\n",
    "    \n",
    "    # dfs\n",
    "    dfs =  np.dstack(\n",
    "        [\n",
    "            [field_dfs[field][t] if t in field_dfs[field].keys() else 0.0 for t in terms]\n",
    "            for field in fields\n",
    "        ])\n",
    "    \n",
    "    # term occcs\n",
    "    term_occurrences = (field_tfs > 0).astype(int)\n",
    "    \n",
    "    # field occurrences\n",
    "    field_occurrences = term_occurrences.sum(axis=2).reshape(len(results), len(terms), 1)\n",
    "\n",
    "    # field Ns\n",
    "    Nfs = np.array(list(field_Ns.values())).reshape(1,1,len(fields))\n",
    "    \n",
    "    # P of t given F\n",
    "#     print(field_Ns)\n",
    "    p_t_f = term_occurrences * (dfs / Nfs)\n",
    "    p_t_f[p_t_f == 0] = 1.0\n",
    "    \n",
    "    \n",
    "    # P of t given d\n",
    "    p_t_d = field_occurrences / len(fields)\n",
    "    p_t_d[p_t_d == 0] = 1\n",
    "    \n",
    "\n",
    "    q_data['bm25_scores_arr'] = field_scores_\n",
    "    q_data['idf_arr'] = idfs\n",
    "    q_data['df_arr'] = dfs\n",
    "    q_data['global_idf_arr'] = global_idfs\n",
    "    q_data['global_df_arr'] = global_dfs\n",
    "    q_data['df_arr'] = dfs\n",
    "    q_data['t_occs'] = term_occurrences\n",
    "    q_data['f_occs'] = field_occurrences\n",
    "    q_data['Nfs'] = Nfs\n",
    "    q_data['p_t_f'] = p_t_f\n",
    "    q_data['p_t_d'] = p_t_d\n",
    "    q_data['doc_ids'] = doc_ids\n",
    "    q_data['avgfl'] = np.array(list(avg_fl_dict.values())).reshape(1,1,len(fields))\n",
    "    q_data['bm25f_scores'] = dict(zip(q_data['bm25f_doc_ids'],q_data['bm25f_score']))\n",
    "    all_query_data[q_id] = q_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "714415ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if catchall field is used, add this field to all the query_data dictionaries in all_query_data\n",
    "if catch_all:\n",
    "    fields = fields + ['all']\n",
    "    for query_id, data in all_query_data.items():\n",
    "        # add meta data things\n",
    "\n",
    "        data['fl_arr'] = np.dstack([data['fl_arr'],data['fl_arr'].sum(axis=2)])\n",
    "        data['tf_arr'] = np.dstack([data['tf_arr'],data['tf_arr'].sum(axis=2)])\n",
    "        data['idf_arr'] = np.dstack([data['idf_arr'], data['global_idf_arr']])\n",
    "        data['df_arr'] = np.dstack([data['df_arr'], data['global_df_arr']])\n",
    "        data['avgfl'] = np.dstack([data['avgfl'],data['avgfl'].sum(axis=2)])\n",
    "\n",
    "        # new dimenstion to tf_occs\n",
    "        data['t_occs'] = np.dstack([data['t_occs'], data['t_occs'].max(axis=2)])\n",
    "\n",
    "        # add field occ due to new field\n",
    "        data['f_occs'][data['f_occs'] > 0] += 1\n",
    "        \n",
    "        ptf_ca = data['t_occs'][:,:,-1] * (data['global_df_arr'] / datasetInfo[index_name]['total_doc_count'])\n",
    "        ptf_ca[ptf_ca == 0] = 1.0\n",
    "\n",
    "        data['p_t_f'] = np.dstack([data['p_t_f'], ptf_ca])\n",
    "        # add field for ptd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "813b0bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_score(query_data,b=0.8,k_1=1.6,catch_all=False):\n",
    "    \"\"\"\n",
    "    function to calculate bm25 scores for a given query based on the results\n",
    "    \"\"\"\n",
    "    terms = query_data['query'].split(' ')\n",
    "    tf_array = query_data['tf_arr']\n",
    "    dls = query_data['fl_arr']\n",
    "    avgfl = query_data['avgfl']\n",
    "    idf_arr = query_data['idf_arr']\n",
    "    if catch_all:\n",
    "        tf_array = np.dstack([tf_array,tf_array.sum(axis=2)])\n",
    "        dls = np.dstack([dls,dls.sum(axis=2)])\n",
    "        idf_arr = np.dstack([idf_arr, query_data['global_idf_arr']])\n",
    "        avgfl = np.dstack([avgfl,avgfl.sum(axis=2)])\n",
    "        \n",
    "    len_norm_tf = tf_array / ((b*dls / avgfl + (1-b)))\n",
    "    \n",
    "    bm25_TF = len_norm_tf / (k_1 + len_norm_tf)\n",
    "    bm25_score_per_term = bm25_TF * idf_arr\n",
    "    bm25_score = bm25_score_per_term.sum(axis=1)\n",
    "    query_data['bm25_scores'] = bm25_score\n",
    "#     return bm25_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f362bdeb",
   "metadata": {},
   "source": [
    "## FSA-BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e8841f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate bm25 score for each documents in the results for each query\n",
    "for query_id, query_data in all_query_data.items(): \n",
    "    bm25_score(query_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f414d8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_aggregate(field_scores,weights=[1.0 for x in fields],catch_all=False):\n",
    "    \"\"\"\n",
    "    function that linearily aggregates the BM25 scores across fields\n",
    "    \"\"\"\n",
    "    weights=[1.0 for x in range(field_scores.shape[1])]\n",
    "    weighted_scores = field_scores * np.array(weights)\n",
    "    return weighted_scores.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ff843bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg10:  0.6212\n",
      "map:  0.2099\n"
     ]
    }
   ],
   "source": [
    "# This cell implements the FSA-BM25 model\n",
    "ndcgs10 = []\n",
    "ndcgs100 = []\n",
    "aps = []\n",
    "# q_ids_ = []\n",
    "for query_id, query_data in all_query_data.items():\n",
    "    query_id = query_id.strip()\n",
    "#     q_ids_.append(query_id)\n",
    "    q_qrels = qrel_dict[query_id]\n",
    "    field_scores = query_data['bm25_scores']\n",
    "    if field_scores.size != 0:\n",
    "        aggregated_scores = linear_aggregate(field_scores)\n",
    "        q_ranking = dict(zip(query_data['doc_ids'], aggregated_scores.tolist()))\n",
    "        query_data['ranking'] = q_ranking\n",
    "\n",
    "        q_ndcg10 = calc_ndcg(query_id, q_ranking, q_qrels,10)\n",
    "        ndcgs10.append(q_ndcg10)\n",
    "\n",
    "        q_ndcg100 = calc_ndcg(query_id, q_ranking, q_qrels,100)\n",
    "        ndcgs100.append(q_ndcg100)\n",
    "\n",
    "        q_ap = calc_ap(query_id, q_ranking, q_qrels)\n",
    "        aps.append(q_ap)\n",
    "    else:\n",
    "        print('miss')\n",
    "        aps.append(0)\n",
    "        ndcgs10.append(0)\n",
    "        ndcgs100.append(0)\n",
    "\n",
    "    \n",
    "ndcg_ds10 = np.round(np.mean(ndcgs10),4)\n",
    "ndcg_ds100 = np.round(np.mean(ndcgs100),4)\n",
    "map_ds = np.round(np.mean(aps),4)\n",
    "\n",
    "save_q_based(index_name, 'map', aps,'bm25lin')\n",
    "save_q_based(index_name, 'ndcg', ndcgs100,'bm25lin')\n",
    "\n",
    "    \n",
    "accuracy_dict['map']['bm25_lin'] = map_ds\n",
    "accuracy_dict['ndcg10']['bm25_lin'] = ndcg_ds10\n",
    "print('ndcg10: ', ndcg_ds10)\n",
    "print('map: ', map_ds)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38667962",
   "metadata": {},
   "source": [
    "## BM25F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b7d60fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25f_score(query_data,b=0.8,k_1=1.6, weights = np.array([1.0 for x in fields]).reshape(1,1,len(fields))):\n",
    "    tf_array = query_data['tf_arr']\n",
    "    dls = query_data['fl_arr']\n",
    "    avgfl = query_data['avgfl']\n",
    "    idf_arr = query_data['global_idf_arr']\n",
    "    len_norm_tf = tf_array / (((1-b) + b*dls / avgfl))\n",
    "    len_norm_tf_weighted = len_norm_tf * weights\n",
    "    len_norm_tf_concat = len_norm_tf_weighted.sum(axis=2)\n",
    "    bm25_TF = (len_norm_tf_concat / (k_1 + len_norm_tf_concat))\n",
    "    bm25_score_per_term = (bm25_TF * idf_arr)\n",
    "    bm25_score = bm25_score_per_term.sum(axis=1)\n",
    "    return bm25_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aeff6510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg10:  0.4422\n",
      "map:  0.2165\n"
     ]
    }
   ],
   "source": [
    "# This cell implements the BM25F model\n",
    "aps = []\n",
    "ndcgs10 = []\n",
    "ndcgs100 = []\n",
    "for query_id, query_data in all_query_data.items():\n",
    "    query_id = query_id.strip()\n",
    "    q_qrels = qrel_dict[query_id]\n",
    "    aggregated_scores = bm25f_score(query_data)\n",
    "    \n",
    "    q_ranking = dict(zip(query_data['doc_ids'], aggregated_scores.tolist()))\n",
    "    query_data['ranking'] = q_ranking\n",
    "    \n",
    "    q_ndcg10 = calc_ndcg(query_id, q_ranking, q_qrels,10)\n",
    "    ndcgs10.append(q_ndcg10)\n",
    "    \n",
    "    q_ndcg100 = calc_ndcg(query_id, q_ranking, q_qrels,100)\n",
    "    ndcgs100.append(q_ndcg100)\n",
    "    \n",
    "    \n",
    "    q_ap = calc_ap(query_id, q_ranking, q_qrels)\n",
    "    aps.append(q_ap)\n",
    "#     print(query_id, q_ndcg)\n",
    "ndcg_ds10 = np.round(np.mean(ndcgs10),4)\n",
    "ndcg_ds100 = np.round(np.mean(ndcgs100),4)\n",
    "map_ds = np.round(np.mean(aps),4)\n",
    "\n",
    "save_q_based(index_name, 'map', aps,'bm25f')\n",
    "save_q_based(index_name, 'ndcg', ndcgs100,'bm25f')\n",
    "\n",
    "accuracy_dict['map']['bm25f'] = map_ds\n",
    "accuracy_dict['ndcg10']['bm25f'] = ndcg_ds10\n",
    "print('ndcg10: ', ndcg_ds10)\n",
    "print('map: ', map_ds)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d2275",
   "metadata": {},
   "source": [
    "## BM25FSimple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fdb32fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25f_score_simple(query_data,b=0.8,k_1=1.6, weights = np.array([1.0 for x in fields]).reshape(1,1,len(fields))):\n",
    "    tf_array = query_data['tf_arr']\n",
    "    dls = query_data['fl_arr'].sum(axis=1).sum(axis=1).reshape(tf_array.shape[0],1)\n",
    "\n",
    "    avgfl = query_data['global_avgdl']\n",
    "\n",
    "    idf_arr = query_data['global_idf_arr']\n",
    "    weighted_tf_array = tf_array * weights\n",
    "    weighted_tf_array_concat = weighted_tf_array.sum(axis=2)\n",
    "    bm25_TF = weighted_tf_array_concat / (k_1*((1-b)+b*(dls / avgfl)) + weighted_tf_array_concat)\n",
    "    bm25_score_per_term = (bm25_TF * idf_arr)\n",
    "    bm25_score = bm25_score_per_term.sum(axis=1)\n",
    "    return bm25_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a88745a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg10:  0.4422\n",
      "map:  0.2168\n"
     ]
    }
   ],
   "source": [
    "# This cell implements the BM25FSimple model\n",
    "aps = []\n",
    "ndcgs10 = []\n",
    "ndcgs100 = []\n",
    "for query_id, query_data in all_query_data.items():\n",
    "    query_id = query_id.strip()\n",
    "    q_qrels = qrel_dict[query_id]\n",
    "    if query_data['tf_arr'].size != 0 and field_scores.size != 0:\n",
    "        aggregated_scores = bm25f_score_simple(query_data)\n",
    "\n",
    "        q_ranking = dict(zip(query_data['doc_ids'], aggregated_scores.tolist()))\n",
    "        query_data['ranking'] = q_ranking\n",
    "\n",
    "        q_ndcg10 = calc_ndcg(query_id, q_ranking, q_qrels,10)\n",
    "        ndcgs10.append(q_ndcg10)\n",
    "\n",
    "        q_ndcg100 = calc_ndcg(query_id, q_ranking, q_qrels,100)\n",
    "        ndcgs100.append(q_ndcg100)\n",
    "\n",
    "        q_ap = calc_ap(query_id, q_ranking, q_qrels)\n",
    "        aps.append(q_ap)\n",
    "    else:\n",
    "        aps.append(0)\n",
    "        ndcgs10.append(0)\n",
    "        ndcgs100.append(0)\n",
    "\n",
    "ndcg_ds10 = np.round(np.mean(ndcgs10),4)\n",
    "ndcg_ds100 = np.round(np.mean(ndcgs100),4)\n",
    "map_ds = np.round(np.mean(aps),4)\n",
    "accuracy_dict['map']['bm25fSimple'] = map_ds\n",
    "accuracy_dict['ndcg10']['bm25fSimple'] = ndcg_ds10\n",
    "\n",
    "save_q_based(index_name, 'map', aps,'bm25fSimple')\n",
    "save_q_based(index_name, 'ndcg', ndcgs100,'bm25fSimple')\n",
    "print('ndcg10: ', ndcg_ds10)\n",
    "print('map: ', map_ds)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523a2797",
   "metadata": {},
   "source": [
    "\n",
    "## ICFW-G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc7418f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_G(query_idfs, query_dfs, empty_fields, N_total, nr_fields):\n",
    "    \"\"\"\n",
    "    Function to calculate the lambda values for ICFW-G\n",
    "    \"\"\"\n",
    "    dfs = query_dfs\n",
    "    idfs = query_idfs\n",
    "    empty_fields = empty_fields\n",
    "    N_total = N_total\n",
    "    N = np.array(N_total)\n",
    "    \n",
    "\n",
    "    nr_fields = nr_fields\n",
    "\n",
    "    df_arr = np.array(list(query_data['global_dfs'].values()))\n",
    "    idf_arr = np.array(list(query_data['global_idfs'].values()))\n",
    "    nr_terms = df_arr.shape[0]\n",
    "    if nr_terms == 1:\n",
    "        shape = (nr_fields.shape[0],1 )\n",
    "        lambda_= np.zeros(shape)\n",
    "        return lambda_, 1\n",
    "    \n",
    "    max_dfs = df_arr.max()\n",
    "    min_dfs = df_arr.min()\n",
    "\n",
    "\n",
    "\n",
    "    non_zero_dfs = df_arr[df_arr > 0]\n",
    "    if not non_zero_dfs[non_zero_dfs != non_zero_dfs.max()].any():\n",
    "        min_df = np.nan\n",
    "    else:\n",
    "        min_df = np.mean(non_zero_dfs)\n",
    "\n",
    "    idf_ratio = idf_arr.max() / idf_arr.min()\n",
    "    max_idf = np.log((N + 0.5) / (min_dfs + 0.5))\n",
    "    min_idf = np.log((N + 0.5) / (max_dfs + 0.5))\n",
    "    idf_ratio = np.log((N + 0.5) / (min_dfs + 0.5)) / np.log((N + 0.5) / (max_dfs + 0.5))\n",
    "    \n",
    "    \n",
    "    Z = idf_ratio\n",
    "#     Z = \n",
    "    numerator = np.log((max_dfs*N**Z) / ((min_dfs**Z)*N))\n",
    "    denominator = np.log((len(fields)**(2*Z)*nr_fields**(Z+1)) / (nr_fields **(2*Z)))\n",
    "    lambda_ = numerator / denominator\n",
    "\n",
    "    lambda_[np.isnan(lambda_)] = 0\n",
    "    lambda_[np.isinf(lambda_)] = 0\n",
    "    return lambda_, Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "134bc42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg10:  0.5712\n",
      "map:  0.2917\n"
     ]
    }
   ],
   "source": [
    "# This cell implements the ICFW-G-BM25 model\n",
    "\n",
    "ndcgs10 = []\n",
    "ndcgs100 = []\n",
    "aps = []\n",
    "lambdas_ = []\n",
    "q_accs = []\n",
    "count = 0\n",
    "for query_id, query_data in all_query_data.items():\n",
    "#     print(count, '/',len(all_query_data))\n",
    "    query_id = query_id.strip()\n",
    "    q_qrels = qrel_dict[query_id]\n",
    "    field_scores = query_data['bm25_scores'] \n",
    "    \n",
    "    query_idfs = query_data['global_idfs']\n",
    "    query_dfs = query_data['global_dfs']\n",
    "    if field_scores.size != 0:\n",
    "\n",
    "        empty_fields = datasetInfo[index_name]['empty_fields']\n",
    "        N_total = datasetInfo[index_name]['total_doc_count']\n",
    "        dls_squueze = query_data['fl_arr'].reshape(field_scores.shape[0],len(fields))\n",
    "        nr_fields = (dls_squueze > 0).sum(axis=1)[np.newaxis].T\n",
    "        lambda_, Z = lambda_G(query_idfs, query_dfs, empty_fields, N_total, nr_fields)\n",
    "\n",
    "\n",
    "        p_t_d = query_data['p_t_d']\n",
    "        p_t_f = query_data['p_t_f']\n",
    "        inf_f_d = -np.log(p_t_d.prod(axis=1))\n",
    "        inf_f_F = -np.log(p_t_f.prod(axis=1))\n",
    "\n",
    "        field_weights = inf_f_F + inf_f_d * lambda_\n",
    "        weighted_arr = field_weights * field_scores\n",
    "        aggregated_scores = weighted_arr.sum(axis=1)\n",
    "\n",
    "        q_ranking = dict(zip(query_data['doc_ids'], aggregated_scores.tolist()))\n",
    "        query_data['ranking'] = q_ranking\n",
    "\n",
    "        q_ndcg10 = calc_ndcg(query_id, q_ranking, q_qrels,10)\n",
    "        ndcgs10.append(q_ndcg10)\n",
    "\n",
    "        q_ndcg100 = calc_ndcg(query_id, q_ranking, q_qrels,100)\n",
    "        ndcgs100.append(q_ndcg100)\n",
    "\n",
    "        q_ap = calc_ap(query_id, q_ranking, q_qrels)\n",
    "        aps.append(q_ap)\n",
    "\n",
    "        lambdas_.append(lambda_)\n",
    "        q_accs.append(q_ap)\n",
    "    else:\n",
    "\n",
    "        print('miss')\n",
    "        aps.append(0)\n",
    "        ndcgs10.append(0)\n",
    "        ndcgs100.append(0)\n",
    "    \n",
    "\n",
    "ndcg_ds10 = np.round(np.mean(ndcgs10),4)\n",
    "ndcg_ds100 = np.round(np.mean(ndcgs100),4)\n",
    "map_ds = np.round(np.mean(aps),4)\n",
    "accuracy_dict['map']['icfw-G'] = map_ds\n",
    "accuracy_dict['ndcg10']['icfw-G'] = ndcg_ds10\n",
    "accuracy_dict['ndcg100']['icfw-G'] = ndcg_ds100\n",
    "save_q_based(index_name, 'map', aps,'icfw-G')\n",
    "print('ndcg10: ', ndcg_ds10)\n",
    "print('map: ', map_ds)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dbe190",
   "metadata": {},
   "source": [
    "\n",
    "## ICFW-GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa015417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_GA(query_idfs, query_dfs, empty_fields, N_total, nr_fields):\n",
    "    \"\"\"\n",
    "    Function to calculate the lambda values for ICFW-GA\n",
    "    \"\"\"\n",
    "    dfs = query_dfs\n",
    "    idfs = query_idfs\n",
    "    empty_fields = empty_fields\n",
    "    N_total = N_total\n",
    "    N = np.array(N_total)\n",
    "    \n",
    "\n",
    "    nr_fields = nr_fields\n",
    "\n",
    "    df_arr = np.array(list(query_data['global_dfs'].values()))\n",
    "    idf_arr = np.array(list(query_data['global_idfs'].values()))\n",
    "    nr_terms = df_arr.shape[0]\n",
    "    if nr_terms == 1:\n",
    "        shape = (nr_fields.shape[0],1 )\n",
    "        lambda_= np.zeros(shape)\n",
    "        return lambda_, 1\n",
    "    \n",
    "    max_dfs = df_arr.max()\n",
    "    min_dfs = df_arr[df_arr!=max_dfs].mean()\n",
    "\n",
    "\n",
    "\n",
    "    non_zero_dfs = df_arr[df_arr > 0]\n",
    "    if not non_zero_dfs[non_zero_dfs != non_zero_dfs.max()].any():\n",
    "        min_df = np.nan\n",
    "    else:\n",
    "        min_df = np.mean(non_zero_dfs)\n",
    "\n",
    "\n",
    "    idf_min = idf_arr.min()\n",
    "    idf_max = idf_arr[idf_arr!=idf_min].mean()\n",
    "    \n",
    "    idf_ratio = idf_max / idf_min\n",
    "    idf_ratio = np.log((N + 0.5) / (min_dfs + 0.5)) / np.log((N + 0.5) / (max_dfs + 0.5))\n",
    "    Z = idf_ratio\n",
    "    numerator = np.log((max_dfs*N**Z) / ((min_dfs**Z)*N))\n",
    "    denominator = np.log((len(fields)**(2*Z)*nr_fields**(Z+1)) / (nr_fields **(2*Z)))\n",
    "    lambda_ = numerator / denominator\n",
    "\n",
    "    lambda_[np.isnan(lambda_)] = 0\n",
    "    lambda_[np.isinf(lambda_)] = 0\n",
    "    return lambda_, Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81167352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg10:  0.5779\n",
      "map:  0.2914\n"
     ]
    }
   ],
   "source": [
    "# This cell implements the ICFW-GA-BM25 model\n",
    "ndcgs10 = []\n",
    "ndcgs100 = []\n",
    "aps = []\n",
    "lambdas_ = []\n",
    "q_accs = []\n",
    "for query_id, query_data in all_query_data.items():\n",
    "    query_id = query_id.strip()\n",
    "    q_qrels = qrel_dict[query_id]\n",
    "    field_scores = query_data['bm25_scores'] \n",
    "\n",
    "    \n",
    "    query_idfs = query_data['global_idfs']\n",
    "    query_dfs = query_data['global_dfs']\n",
    "    if field_scores.size != 0:\n",
    "\n",
    "        empty_fields = datasetInfo[index_name]['empty_fields']\n",
    "        N_total = datasetInfo[index_name]['total_doc_count']\n",
    "        dls_squueze = query_data['fl_arr'].reshape(field_scores.shape[0],len(fields))\n",
    "        nr_fields = (dls_squueze > 0).sum(axis=1)[np.newaxis].T\n",
    "        lambda_, Z = lambda_GA(query_idfs, query_dfs, empty_fields, N_total, nr_fields)\n",
    "\n",
    "\n",
    "        p_t_d = query_data['p_t_d']\n",
    "        p_t_f = query_data['p_t_f']\n",
    "        inf_f_d = -np.log(p_t_d.prod(axis=1))\n",
    "        inf_f_F = -np.log(p_t_f.prod(axis=1))\n",
    "\n",
    "        field_weights = inf_f_F + inf_f_d * lambda_\n",
    "        weighted_arr = field_weights * field_scores\n",
    "        aggregated_scores = weighted_arr.sum(axis=1)\n",
    "\n",
    "        q_ranking = dict(zip(query_data['doc_ids'], aggregated_scores.tolist()))\n",
    "        query_data['ranking'] = q_ranking\n",
    "\n",
    "        q_ndcg10 = calc_ndcg(query_id, q_ranking, q_qrels,10)\n",
    "        ndcgs10.append(q_ndcg10)\n",
    "\n",
    "        q_ndcg100 = calc_ndcg(query_id, q_ranking, q_qrels,100)\n",
    "        ndcgs100.append(q_ndcg100)\n",
    "\n",
    "        q_ap = calc_ap(query_id, q_ranking, q_qrels)\n",
    "        aps.append(q_ap)\n",
    "\n",
    "        lambdas_.append(lambda_)\n",
    "        q_accs.append(q_ap)\n",
    "    else:\n",
    "\n",
    "        print('miss')\n",
    "        aps.append(0)\n",
    "        ndcgs10.append(0)\n",
    "        ndcgs100.append(0)\n",
    "    \n",
    "\n",
    "ndcg_ds10 = np.round(np.mean(ndcgs10),4)\n",
    "ndcg_ds100 = np.round(np.mean(ndcgs100),4)\n",
    "map_ds = np.round(np.mean(aps),4)\n",
    "accuracy_dict['map']['icfw-GA'] = map_ds\n",
    "accuracy_dict['ndcg10']['icfw-GA'] = ndcg_ds10\n",
    "accuracy_dict['ndcg100']['icfw-GA'] = ndcg_ds100\n",
    "save_q_based(index_name, 'map', aps,'icfw-GA')\n",
    "print('ndcg10: ', ndcg_ds10)\n",
    "print('map: ', map_ds)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7d51ac",
   "metadata": {},
   "source": [
    "## ICFW-LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ed68a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_LA(query_idfs, query_dfs, empty_fields, N_total, nr_fields):\n",
    "    \"\"\"\n",
    "    Function to calculate the lambda values for ICFW-LA\n",
    "    \"\"\"\n",
    "    k_1 = 1.6\n",
    "    dfs = query_dfs\n",
    "    idfs = query_idfs\n",
    "    empty_fields = empty_fields\n",
    "    N_total = N_total\n",
    "    N = [N_total - empty_fields[field] for field in fields]\n",
    "    N = np.array(N)\n",
    "    \n",
    "    nr_fields = nr_fields\n",
    "\n",
    "    df_arr = query_dfs\n",
    "    idf_arr = query_idfs\n",
    "    \n",
    "    nr_terms = df_arr.shape[1]\n",
    "    if nr_terms == 1:\n",
    "        shape = (nr_fields.shape[0],1 )\n",
    "        lambda_= np.zeros(shape)\n",
    "        return lambda_, None\n",
    "\n",
    "    max_dfs = df_arr.mean(axis=1).max()\n",
    "    min_dfs = df_arr.mean(axis=1).mean()\n",
    "    min_dfs = df_arr[df_arr!=max_dfs].mean()\n",
    "\n",
    "    idf_ratio = np.log((N + 0.5) / (min_dfs + 0.5)) / np.log((N + 0.5) / (max_dfs + 0.5))\n",
    "    idf_ratio = query_idfs.mean(axis=1).max()  / query_idfs[query_idfs!=query_idfs.min()].mean()\n",
    "    Z = idf_ratio\n",
    "\n",
    "    numerator = np.log((max_dfs*N**Z) / ((min_dfs**Z)*N))\n",
    "    denominator = np.log((2**(2*Z)*nr_fields**(Z+1)) / (nr_fields **(2*Z)))\n",
    "    lambda_ = numerator / denominator\n",
    "\n",
    "    lambda_[np.isnan(lambda_)] = 0\n",
    "    lambda_[np.isinf(lambda_)] = 0\n",
    "    lambda_[lambda_ < 0] = 0\n",
    "    return lambda_, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "921aa263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg10:  0.5779\n",
      "map:  0.293\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This cell implements the ICFW-LA-BM25 model\n",
    "ndcgs10 = []\n",
    "ndcgs100 = []\n",
    "aps = []\n",
    "lambdas_ = []\n",
    "\n",
    "for query_id, query_data in all_query_data.items():\n",
    "    query_id = query_id.strip()\n",
    "    q_qrels = qrel_dict[query_id]\n",
    "    field_scores = query_data['bm25_scores'] \n",
    "\n",
    "    \n",
    "    query_idfs = query_data['idf_arr']\n",
    "    query_dfs = query_data['df_arr']\n",
    "\n",
    "    if field_scores.size != 0:\n",
    "        empty_fields = datasetInfo[index_name]['empty_fields']\n",
    "        N_total = datasetInfo[index_name]['total_doc_count']\n",
    "        dls_squueze = query_data['fl_arr'].reshape(field_scores.shape[0],len(fields))\n",
    "        nr_fields = (dls_squueze > 0).sum(axis=1)[np.newaxis].T\n",
    "        lambda_, Z = lambda_LA(query_idfs, query_dfs, empty_fields, N_total, nr_fields)\n",
    "\n",
    "        p_t_d = query_data['p_t_d']\n",
    "        p_t_f = query_data['p_t_f']\n",
    "        inf_f_d = -np.log(p_t_d.prod(axis=1))\n",
    "        inf_f_F = -np.log(p_t_f.prod(axis=1))\n",
    "\n",
    "        field_weights = inf_f_F + inf_f_d * lambda_\n",
    "        weighted_arr = field_weights * field_scores\n",
    "        aggregated_scores = weighted_arr.sum(axis=1)\n",
    "        q_ranking = dict(zip(query_data['doc_ids'], aggregated_scores.tolist()))\n",
    "        query_data['ranking'] = q_ranking\n",
    "\n",
    "        q_ndcg10 = calc_ndcg(query_id, q_ranking, q_qrels,10)\n",
    "        ndcgs10.append(q_ndcg10)\n",
    "\n",
    "        q_ndcg100 = calc_ndcg(query_id, q_ranking, q_qrels,100)\n",
    "        ndcgs100.append(q_ndcg100)\n",
    "\n",
    "        q_ap = calc_ap(query_id, q_ranking, q_qrels)\n",
    "        aps.append(q_ap)\n",
    "        lambdas_.append(lambda_)\n",
    "    else:\n",
    "\n",
    "        print('miss')\n",
    "        aps.append(0)\n",
    "        ndcgs100.append(0)\n",
    "\n",
    "ndcg_ds100 = np.round(np.mean(ndcgs100),4)\n",
    "map_ds = np.round(np.mean(aps),4)\n",
    "accuracy_dict['map']['icfw-LA'] = map_ds\n",
    "accuracy_dict['ndcg10']['icfw-LA'] = ndcg_ds100\n",
    "save_q_based(index_name, 'map', aps,'icfw-LA')\n",
    "save_q_based(index_name, 'ndcg', ndcgs100,'icfw-LA')\n",
    "print('ndcg10: ', ndcg_ds10)\n",
    "print('map: ', map_ds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a4509e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bm25_lin</th>\n",
       "      <td>0.2099</td>\n",
       "      <td>0.6212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bm25f</th>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.4422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bm25fSimple</th>\n",
       "      <td>0.2168</td>\n",
       "      <td>0.4422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>icfw-G</th>\n",
       "      <td>0.2917</td>\n",
       "      <td>0.5712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>icfw-GA</th>\n",
       "      <td>0.2914</td>\n",
       "      <td>0.5779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>icfw-LA</th>\n",
       "      <td>0.2930</td>\n",
       "      <td>0.5275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                map  ndcg@100\n",
       "bm25_lin     0.2099    0.6212\n",
       "bm25f        0.2165    0.4422\n",
       "bm25fSimple  0.2168    0.4422\n",
       "icfw-G       0.2917    0.5712\n",
       "icfw-GA      0.2914    0.5779\n",
       "icfw-LA      0.2930    0.5275"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_dict['ndcg@100'] = accuracy_dict['ndcg10']\n",
    "accuracy_dict_ = {k:v for k,v in accuracy_dict.items() if k not in ['ndcg100','ndcg10']}\n",
    "acc_df = pd.DataFrame(accuracy_dict_)\n",
    "\n",
    "acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f54b1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bfd3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
